{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "file_list = []\n",
    "class_list = []\n",
    "\n",
    "DATADIR = \".\"\n",
    "\n",
    "# All the categories I want my neural network to detect\n",
    "CATEGORIES = [\"deer\",\"brown bear\",\"snowshoe hare brown\",\"Moose\",\"human\"]\n",
    "\n",
    "# The size of the images that my neural network will use\n",
    "IMG_SIZE = 50\n",
    "\n",
    "# Checking or all images in the data folder\n",
    "for category in CATEGORIES :\n",
    "    path = os.path.join(DATADIR, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES :\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try :\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "random.shuffle(training_data) #to avoid overfitting\n",
    "\n",
    "X = [] #features\n",
    "y = [] #labels\n",
    "\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1) #-1 is unknown dimension\n",
    "\n",
    "# Creating the files containing all the information about my model\n",
    "pickle_out = open(\"X.pickle\", \"wb\") #wb for write buffer\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_in = open(\"X.pickle\", \"rb\") #rb for read buffer\n",
    "X = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 531 samples, validate on 59 samples\n",
      "Epoch 1/40\n",
      "531/531 [==============================] - 5s 9ms/step - loss: 1.6653 - acc: 0.5669 - val_loss: 1.3359 - val_acc: 0.5932\n",
      "Epoch 2/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 1.1653 - acc: 0.6083 - val_loss: 1.3075 - val_acc: 0.5932\n",
      "Epoch 3/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 1.1022 - acc: 0.6083 - val_loss: 1.2314 - val_acc: 0.5932\n",
      "Epoch 4/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 1.0781 - acc: 0.6083 - val_loss: 1.1601 - val_acc: 0.5932\n",
      "Epoch 5/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.9861 - acc: 0.6365 - val_loss: 1.1399 - val_acc: 0.5932\n",
      "Epoch 6/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.8859 - acc: 0.6629 - val_loss: 1.1195 - val_acc: 0.5932\n",
      "Epoch 7/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.8203 - acc: 0.6893 - val_loss: 1.1195 - val_acc: 0.5932\n",
      "Epoch 8/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.8439 - acc: 0.6874 - val_loss: 1.0559 - val_acc: 0.5932\n",
      "Epoch 9/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.7800 - acc: 0.7024 - val_loss: 1.0763 - val_acc: 0.6102\n",
      "Epoch 10/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.7600 - acc: 0.7156 - val_loss: 1.2315 - val_acc: 0.5932\n",
      "Epoch 11/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.7191 - acc: 0.7382 - val_loss: 1.0575 - val_acc: 0.6441\n",
      "Epoch 12/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.6495 - acc: 0.7533 - val_loss: 1.1542 - val_acc: 0.6610\n",
      "Epoch 13/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.6083 - acc: 0.7627 - val_loss: 1.0924 - val_acc: 0.6610\n",
      "Epoch 14/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.5691 - acc: 0.7966 - val_loss: 1.2259 - val_acc: 0.6441\n",
      "Epoch 15/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.5242 - acc: 0.8154 - val_loss: 1.1514 - val_acc: 0.6949\n",
      "Epoch 16/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.5298 - acc: 0.7966 - val_loss: 1.0516 - val_acc: 0.7458\n",
      "Epoch 17/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.4666 - acc: 0.8380 - val_loss: 1.1147 - val_acc: 0.7797\n",
      "Epoch 18/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.4054 - acc: 0.8531 - val_loss: 1.1315 - val_acc: 0.7797\n",
      "Epoch 19/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.3947 - acc: 0.8569 - val_loss: 1.2323 - val_acc: 0.7288\n",
      "Epoch 20/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.3056 - acc: 0.8983 - val_loss: 1.2644 - val_acc: 0.8136\n",
      "Epoch 21/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.2666 - acc: 0.9115 - val_loss: 1.3259 - val_acc: 0.7797\n",
      "Epoch 22/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.2595 - acc: 0.9228 - val_loss: 1.4544 - val_acc: 0.7288\n",
      "Epoch 23/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.2656 - acc: 0.9077 - val_loss: 1.3534 - val_acc: 0.7966\n",
      "Epoch 24/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.2094 - acc: 0.9303 - val_loss: 1.5407 - val_acc: 0.7458\n",
      "Epoch 25/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.1657 - acc: 0.9510 - val_loss: 1.6087 - val_acc: 0.7458\n",
      "Epoch 26/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.1493 - acc: 0.9605 - val_loss: 1.7596 - val_acc: 0.7288\n",
      "Epoch 27/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.2088 - acc: 0.9284 - val_loss: 1.3230 - val_acc: 0.7966\n",
      "Epoch 28/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.2101 - acc: 0.9341 - val_loss: 1.5170 - val_acc: 0.7627\n",
      "Epoch 29/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.1104 - acc: 0.9642 - val_loss: 1.5482 - val_acc: 0.7627\n",
      "Epoch 30/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.0919 - acc: 0.9718 - val_loss: 1.5224 - val_acc: 0.7797\n",
      "Epoch 31/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.0846 - acc: 0.9774 - val_loss: 1.6107 - val_acc: 0.7627\n",
      "Epoch 32/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.0762 - acc: 0.9831 - val_loss: 1.7224 - val_acc: 0.7627\n",
      "Epoch 33/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.0914 - acc: 0.9736 - val_loss: 1.5415 - val_acc: 0.7966\n",
      "Epoch 34/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.0599 - acc: 0.9868 - val_loss: 1.6513 - val_acc: 0.7627\n",
      "Epoch 35/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.0662 - acc: 0.9774 - val_loss: 1.7111 - val_acc: 0.7797\n",
      "Epoch 36/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.0537 - acc: 0.9812 - val_loss: 1.8236 - val_acc: 0.7458\n",
      "Epoch 37/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.0482 - acc: 0.9887 - val_loss: 1.9036 - val_acc: 0.7627\n",
      "Epoch 38/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.0593 - acc: 0.9812 - val_loss: 1.7681 - val_acc: 0.7797\n",
      "Epoch 39/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.0445 - acc: 0.9887 - val_loss: 1.6399 - val_acc: 0.7797\n",
      "Epoch 40/40\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 0.0338 - acc: 0.9925 - val_loss: 1.7028 - val_acc: 0.7797\n",
      "Saved model to disk\n",
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8c6c72a470>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Opening the files about data\n",
    "X = pickle.load(open(\"X.pickle\", \"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\", \"rb\"))\n",
    "\n",
    "# normalizing data (a pixel goes from 0 to 255)\n",
    "X = X/255.0\n",
    "\n",
    "# Building the model\n",
    "model = Sequential()\n",
    "# 3 convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), input_shape = X.shape[1:]))\n",
    "model.add(Activation(\"relu\")) #nonlinear activation functions are important because the function you are trying to learn is usually nonlinear. If nonlinear activation functions weren’t used, the net would be a large linear classifier, and could be simplified by simply multiplying the weight matrices together (accounting for bias). It wouldn’t be able to do anything interesting, such as image classification or text prediction.\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) #Pooling layers are used to generalize the output of the convolutional layers. Along with generalizing, it also reduces the number of parameters in the model by down-sampling the output of the convolutional layer.\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 2 hidden layers\n",
    "model.add(Flatten()) #Flatten layer converts the output of convolutional layers into a one dimensional feature vector. It is important to flatten the outputs because Dense (Fully connected) layers only accept a feature vector as input.\n",
    "model.add(Dense(5))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(5))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# The output layer with 5 neurons, for 5 classes\n",
    "model.add(Dense(5))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "# Compiling the model using some basic parameters\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Training the model, with 40 iterations\n",
    "# validation_split corresponds to the percentage of images used for the validation phase compared to all the images\n",
    "history = model.fit(X, y, batch_size=32, epochs=40, validation_split=0.1)\n",
    "\n",
    "# Saving the model\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file :\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "model.save('CNN.model')\n",
    "\n",
    "# Printing a graph showing the accuracy changes during the training phase\n",
    "print(history.history.keys())\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/human2.jpg\n",
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "test/deer2.jpg\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "test/moose.jpeg\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "test/snowshoe hare brown2.jpg\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "test/snowshoe hare brown.jpg\n",
      "[[4.268976e-15 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00\n",
      "  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      "  0.000000e+00 0.000000e+00 0.000000e+00]]\n",
      "test/human.jpg\n",
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "                        Filename      Predicted Label\n",
      "0                test/human2.jpg                human\n",
      "1                 test/deer2.jpg                 deer\n",
      "2                test/moose.jpeg                Moose\n",
      "3  test/snowshoe hare brown2.jpg  snowshoe hare brown\n",
      "4   test/snowshoe hare brown.jpg                human\n",
      "5                 test/human.jpg                human\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "CATEGORIES = [\"deer\",\"brown bear\",\"snowshoe hare brown\",\"Moose\",\"human\"]\n",
    "\n",
    "#Preaparing the image for prediction\n",
    "def prepare(file):\n",
    "    IMG_SIZE = 50\n",
    "    img_array = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "#Predicting the animal in the image\n",
    "def predict(path,count):\n",
    "    print(path)\n",
    "    df.at[count, 'Filename'] = path\n",
    "    model = tf.keras.models.load_model(\"CNN.model\")\n",
    "    image = prepare(path)\n",
    "    prediction = model.predict([image])\n",
    "    print(prediction)\n",
    "    prediction = list(prediction[0])\n",
    "    df.at[count, 'Predicted Label'] = CATEGORIES[prediction.index(max(prediction))]\n",
    "#     pd.concat([df,pd.DataFrame([[CATEGORIES[prediction.index(max(prediction))]]], columns=[1] )], axis=0)\n",
    "    \n",
    "df = pd.DataFrame(columns = ['Filename', 'Predicted Label']) \n",
    "count=0\n",
    "for filename in os.listdir('test'):\n",
    "    predict(os.path.join('test',filename),count)\n",
    "    count+=1\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Filename Predicted Label\n",
      "0  Wildlife/11090008.JPG            deer\n",
      "                Filename      Predicted Label\n",
      "0  Wildlife/11090008.JPG                 deer\n",
      "1  Wildlife/09110456.JPG  snowshoe hare brown\n",
      "                Filename      Predicted Label\n",
      "0  Wildlife/11090008.JPG                 deer\n",
      "1  Wildlife/09110456.JPG  snowshoe hare brown\n",
      "2  Wildlife/06170241.JPG                human\n",
      "                Filename      Predicted Label\n",
      "0  Wildlife/11090008.JPG                 deer\n",
      "1  Wildlife/09110456.JPG  snowshoe hare brown\n",
      "2  Wildlife/06170241.JPG                human\n",
      "3  Wildlife/07050290.JPG                Moose\n",
      "                Filename      Predicted Label\n",
      "0  Wildlife/11090008.JPG                 deer\n",
      "1  Wildlife/09110456.JPG  snowshoe hare brown\n",
      "2  Wildlife/06170241.JPG                human\n",
      "3  Wildlife/07050290.JPG                Moose\n",
      "4  Wildlife/08050373.JPG                 deer\n",
      "                Filename      Predicted Label\n",
      "0  Wildlife/11090008.JPG                 deer\n",
      "1  Wildlife/09110456.JPG  snowshoe hare brown\n",
      "2  Wildlife/06170241.JPG                human\n",
      "3  Wildlife/07050290.JPG                Moose\n",
      "4  Wildlife/08050373.JPG                 deer\n",
      "5  Wildlife/07050284.JPG                Moose\n",
      "                Filename      Predicted Label\n",
      "0  Wildlife/11090008.JPG                 deer\n",
      "1  Wildlife/09110456.JPG  snowshoe hare brown\n",
      "2  Wildlife/06170241.JPG                human\n",
      "3  Wildlife/07050290.JPG                Moose\n",
      "4  Wildlife/08050373.JPG                 deer\n",
      "5  Wildlife/07050284.JPG                Moose\n",
      "6  Wildlife/05090154.JPG                Moose\n",
      "                Filename      Predicted Label\n",
      "0  Wildlife/11090008.JPG                 deer\n",
      "1  Wildlife/09110456.JPG  snowshoe hare brown\n",
      "2  Wildlife/06170241.JPG                human\n",
      "3  Wildlife/07050290.JPG                Moose\n",
      "4  Wildlife/08050373.JPG                 deer\n",
      "5  Wildlife/07050284.JPG                Moose\n",
      "6  Wildlife/05090154.JPG                Moose\n",
      "7  Wildlife/09160614.JPG                Moose\n",
      "                Filename      Predicted Label\n",
      "0  Wildlife/11090008.JPG                 deer\n",
      "1  Wildlife/09110456.JPG  snowshoe hare brown\n",
      "2  Wildlife/06170241.JPG                human\n",
      "3  Wildlife/07050290.JPG                Moose\n",
      "4  Wildlife/08050373.JPG                 deer\n",
      "5  Wildlife/07050284.JPG                Moose\n",
      "6  Wildlife/05090154.JPG                Moose\n",
      "7  Wildlife/09160614.JPG                Moose\n",
      "8  Wildlife/02070007.JPG                human\n",
      "                Filename      Predicted Label\n",
      "0  Wildlife/11090008.JPG                 deer\n",
      "1  Wildlife/09110456.JPG  snowshoe hare brown\n",
      "2  Wildlife/06170241.JPG                human\n",
      "3  Wildlife/07050290.JPG                Moose\n",
      "4  Wildlife/08050373.JPG                 deer\n",
      "5  Wildlife/07050284.JPG                Moose\n",
      "6  Wildlife/05090154.JPG                Moose\n",
      "7  Wildlife/09160614.JPG                Moose\n",
      "8  Wildlife/02070007.JPG                human\n",
      "9  Wildlife/09160600.JPG                 deer\n",
      "                 Filename      Predicted Label\n",
      "0   Wildlife/11090008.JPG                 deer\n",
      "1   Wildlife/09110456.JPG  snowshoe hare brown\n",
      "2   Wildlife/06170241.JPG                human\n",
      "3   Wildlife/07050290.JPG                Moose\n",
      "4   Wildlife/08050373.JPG                 deer\n",
      "5   Wildlife/07050284.JPG                Moose\n",
      "6   Wildlife/05090154.JPG                Moose\n",
      "7   Wildlife/09160614.JPG                Moose\n",
      "8   Wildlife/02070007.JPG                human\n",
      "9   Wildlife/09160600.JPG                 deer\n",
      "10  Wildlife/02070013.JPG                 deer\n",
      "                 Filename      Predicted Label\n",
      "0   Wildlife/11090008.JPG                 deer\n",
      "1   Wildlife/09110456.JPG  snowshoe hare brown\n",
      "2   Wildlife/06170241.JPG                human\n",
      "3   Wildlife/07050290.JPG                Moose\n",
      "4   Wildlife/08050373.JPG                 deer\n",
      "5   Wildlife/07050284.JPG                Moose\n",
      "6   Wildlife/05090154.JPG                Moose\n",
      "7   Wildlife/09160614.JPG                Moose\n",
      "8   Wildlife/02070007.JPG                human\n",
      "9   Wildlife/09160600.JPG                 deer\n",
      "10  Wildlife/02070013.JPG                 deer\n",
      "11  Wildlife/05090140.JPG                Moose\n",
      "                 Filename      Predicted Label\n",
      "0   Wildlife/11090008.JPG                 deer\n",
      "1   Wildlife/09110456.JPG  snowshoe hare brown\n",
      "2   Wildlife/06170241.JPG                human\n",
      "3   Wildlife/07050290.JPG                Moose\n",
      "4   Wildlife/08050373.JPG                 deer\n",
      "5   Wildlife/07050284.JPG                Moose\n",
      "6   Wildlife/05090154.JPG                Moose\n",
      "7   Wildlife/09160614.JPG                Moose\n",
      "8   Wildlife/02070007.JPG                human\n",
      "9   Wildlife/09160600.JPG                 deer\n",
      "10  Wildlife/02070013.JPG                 deer\n",
      "11  Wildlife/05090140.JPG                Moose\n",
      "12  Wildlife/09160628.JPG                Moose\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8edaeb5da316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Wildlife'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Wildlife'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mcount\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-8edaeb5da316>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(path, count)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Filename'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CNN.model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    804\u001b[0m                        str(len(weight_values)) + ' elements.')\n\u001b[1;32m    805\u001b[0m     \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m   \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2782\u001b[0m         \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2783\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2784\u001b[0;31m       \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    467\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    736\u001b[0m       \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m       \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "CATEGORIES = [\"deer\",\"brown bear\",\"snowshoe hare brown\",\"Moose\",\"human\"]\n",
    "\n",
    "#Preparing the image for prediction\n",
    "def prepare(file):\n",
    "    IMG_SIZE = 50\n",
    "    img_array = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "#Predicting the animal in the image\n",
    "def predict(path,count):\n",
    "    df.at[count, 'Filename'] = path\n",
    "    model = tf.keras.models.load_model(\"CNN.model\")\n",
    "    image = prepare(path)\n",
    "    prediction = model.predict([image])\n",
    "    prediction = list(prediction[0])\n",
    "    df.at[count, 'Predicted Label'] = CATEGORIES[prediction.index(max(prediction))]\n",
    "#   pd.concat([df,pd.DataFrame([[CATEGORIES[prediction.index(max(prediction))]]], columns=[1] )], axis=0)\n",
    "    \n",
    "df = pd.DataFrame(columns = ['Filename', 'Predicted Label']) \n",
    "count=0\n",
    "for filename in os.listdir('Wildlife'):\n",
    "    predict(os.path.join('Wildlife',filename),count)\n",
    "    count+=1\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
